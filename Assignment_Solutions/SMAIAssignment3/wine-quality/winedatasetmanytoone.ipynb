{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#WineData = pd.read_csv('data.csv',sep=';',index_col = False)\n",
    "#WineData.head()\n",
    "#del AdmissionData['Serial No.']\n",
    "#ran = np.random.rand(len(AdmissionData)) < 0.8\n",
    "#train = AdmissionData[ran]\n",
    "#val = AdmissionData[~ran]\n",
    "#train = WineData.sample(frac = 0.8)\n",
    "#val = WineData.loc[~WineData.index.isin(train.index)]\n",
    "#train.to_csv('UsedTrainingDataForAdmissionDs.csv',sep=';',index = False)\n",
    "#val.to_csv('UsedValidationDataForAdmissionDs.csv',sep=';',index = False)\n",
    "train = pd.read_csv('UsedTrainingDataForWineDs.csv',sep=';',index_col = False)\n",
    "val = pd.read_csv('UsedValidationDataForWineDs.csv',sep=';',index_col = False)\n",
    "#train = pd.read_csv('UsedTrainingDataForAdmissionDs.csv',sep=',',index_col = False)\n",
    "#val = pd.read_csv('UsedValidationDataForAdmissionDs.csv',sep=',',index_col = False)\n",
    "#np.unique(train['quality\"\"\"'])\n",
    "for i in train.index:\n",
    "    train.at[i,'quality\"\"\"'] -= 3\n",
    "for i in val.index:\n",
    "    val.at[i,'quality\"\"\"'] -= 3\n",
    "#np.unique(train['quality\"\"\"'])\n",
    "temptrain = train.loc[:,train.columns != 'quality\"\"\"']\n",
    "new_coltrain = [1]*len(train)\n",
    "temptrain.insert(loc=0, column='intercept', value =new_coltrain)\n",
    "trainXmatrix = temptrain.values\n",
    "trainXmatrix -= np.mean(trainXmatrix,axis = 0)\n",
    "trainXmatrix[:,1:] /= np.std(trainXmatrix.astype(float),axis = 0)[1:]\n",
    "trainXmatrix[:,0] = 1\n",
    "\n",
    "tempval = val.loc[:,val.columns != 'quality\"\"\"']\n",
    "new_colval = [1]*len(val)\n",
    "tempval.insert(loc=0, column='intercept', value=new_colval)\n",
    "valXmatrix = tempval.values\n",
    "valXmatrix -= np.mean(valXmatrix,axis = 0)\n",
    "valXmatrix[:,1:] /= np.std(valXmatrix.astype(float),axis = 0)[1:]\n",
    "valXmatrix[:,0] = 1\n",
    "\n",
    "numOfSamples,numOfdimPlusOne = trainXmatrix.shape\n",
    "#numOfSamples,numOfdimPlusOne\n",
    "\n",
    "theta = np.array([np.array([0.5]*numOfdimPlusOne)]*(len(np.unique(train['quality\"\"\"']))-1))\n",
    "#theta.shape\n",
    "\n",
    "def getSigmoid(x,theta,k):\n",
    "    #x = np.array(x)\n",
    "    #theta = np.array(theta)\n",
    "    numer = np.exp(theta[k]@x)\n",
    "    denom = 1\n",
    "    for index in range(0,len(np.unique(train['quality\"\"\"']))-1):\n",
    "        denom += np.exp(theta[index]@x)   \n",
    "    return numer/denom\n",
    "\n",
    "valYvector = np.array(val['quality\"\"\"'].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration is 0\n",
      "likelyHood is -7192.044017484971\n",
      "iteration is 1\n",
      "likelyHood is -5847.488568566865\n",
      "iteration is 2\n",
      "likelyHood is -5097.044360358322\n",
      "iteration is 3\n",
      "likelyHood is -4692.488332958577\n",
      "iteration is 4\n",
      "likelyHood is -4489.826951229479\n",
      "iteration is 5\n",
      "likelyHood is -4407.693723350362\n",
      "iteration is 6\n",
      "likelyHood is -4403.1782603248685\n",
      "iteration is 7\n",
      "likelyHood is -4399.253068483785\n",
      "iteration is 8\n",
      "likelyHood is -4395.891618116193\n",
      "iteration is 9\n",
      "likelyHood is -4393.068680180523\n",
      "iteration is 10\n",
      "likelyHood is -4390.760259864034\n",
      "iteration is 11\n",
      "likelyHood is -4388.943533461326\n",
      "iteration is 12\n",
      "likelyHood is -4387.596788412448\n",
      "iteration is 13\n",
      "likelyHood is -4386.699366350373\n",
      "iteration is 14\n",
      "likelyHood is -4386.231609017456\n",
      "iteration is 15\n",
      "likelyHood is -4386.174806917386\n"
     ]
    }
   ],
   "source": [
    "#trainYvector = np.array([1.0 if x == eachvalue else 0.0 for x in train['quality\"\"\"']])\n",
    "trainYvector = np.array(train['quality\"\"\"'].copy())\n",
    "#valYvector = np.array([1.0 if x == eachvalue else 0.0 for x in val['quality\"\"\"']])\n",
    "valYvector = np.array(val['quality\"\"\"'].copy())\n",
    "iterations = 0\n",
    "theta = np.array([np.array([0.5]*numOfdimPlusOne)]*(len(np.unique(train['quality\"\"\"']))-1)) #initialization\n",
    "alpha = 0.00005\n",
    "residual = 10\n",
    "likelyHood = 1000\n",
    "#while iterations <50:\n",
    "iterations = 0\n",
    "alpha = 0.0005\n",
    "while residual > 0.0001:    \n",
    "    #beforetheta = theta.copy()\n",
    "    beforelikelyHood = likelyHood\n",
    "    print(\"iteration is \"+str(iterations))\n",
    "    #print(\"theta is \"+str(theta))\n",
    "    likelyHood = 0\n",
    "    iterations += 1\n",
    "    if iterations>5:\n",
    "        alpha = 0.00005\n",
    "    #alpha = (1/((iterations)+1))\n",
    "    for p in range(0,numOfSamples):\n",
    "        if trainYvector[p] >0:\n",
    "            tempSigmoid = getSigmoid(trainXmatrix[p,:],theta,trainYvector[p]-1)\n",
    "            if tempSigmoid > 0:\n",
    "                likelyHood += np.log(tempSigmoid)\n",
    "            else:\n",
    "                likelyHood -= 1000 \n",
    "        else:\n",
    "            tempSum = 0\n",
    "            for index1 in range(0,len(np.unique(train['quality\"\"\"']))-1):\n",
    "                tempSum += getSigmoid(trainXmatrix[p,:],theta,index1)\n",
    "            #tempSigmoid = 1-tempSum\n",
    "            tempSigmoid = (1/1+(tempSum))\n",
    "            if tempSigmoid > 0:\n",
    "                likelyHood += np.log(tempSigmoid)\n",
    "            else:\n",
    "                likelyHood -= 1000                \n",
    "    print(\"likelyHood is \"+str(likelyHood))  \n",
    "\n",
    "    for j in range(0,numOfdimPlusOne):\n",
    "        for k in range(1,len(np.unique(train['quality\"\"\"']))):\n",
    "            tempj = 0\n",
    "            for i in range(0,numOfSamples):\n",
    "                if trainYvector[i] > 0 and trainYvector[i]==k:\n",
    "                    tempj += (alpha*(1.0-getSigmoid(trainXmatrix[i,:],theta,k-1))*trainXmatrix[i,j])\n",
    "                if trainYvector[i] == 0: #and trainYvector[i]==k: \n",
    "                    tempj += (alpha*(-getSigmoid(trainXmatrix[i,:],theta,k-1))*trainXmatrix[i,j])\n",
    "            theta[k-1,j] += tempj   \n",
    "    #esidual = np.linalg.norm(theta-beforetheta)\n",
    "    residual = np.linalg.norm(likelyHood-beforelikelyHood)/np.abs(beforelikelyHood)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Convergedtheta = np.array([[ 0.83078752,  0.61170823,  0.86434487,  0.42589804,  0.40172731,\n",
    "         0.58952366,  0.25183323,  0.39515996,  0.55013274,  0.47169646,\n",
    "         0.46386952,  0.38771927],\n",
    "       [ 2.65926724,  0.59296356,  0.79548132,  0.38460576,  0.50019212,\n",
    "         0.76580049,  0.32927432,  0.74481794,  0.97924027,  0.37003593,\n",
    "         0.30668897, -0.36659851],\n",
    "       [ 3.88904982,  0.40768877,  0.14904719,  0.5251274 ,  0.55800554,\n",
    "         0.47123907,  0.47063105,  0.40479518,  0.44967958,  0.41350013,\n",
    "         0.47143144,  0.59351791],\n",
    "       [ 2.03246134,  0.38867073,  0.18400969,  0.45490527,  0.29616396,\n",
    "         0.05572453,  0.45353791,  0.16459671, -0.0728328 ,  0.65185923,\n",
    "         0.61588997,  1.25696314],\n",
    "       [ 0.85174006,  0.44276617,  0.46792521,  0.49716958,  0.44416778,\n",
    "         0.37601619,  0.53172503,  0.400476  ,  0.2916254 ,  0.56778029,\n",
    "         0.50512238,  0.8102274 ],\n",
    "       [ 0.50945773,  0.50076105,  0.50255141,  0.50348996,  0.49148837,\n",
    "         0.48989324,  0.49373858,  0.4910525 ,  0.48446155,  0.51093922,\n",
    "         0.49845555,  0.51969096]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0  0   1    2    3    4   5  6\n",
      "row_0                             \n",
      "1      0   1    0    1    0   0  0\n",
      "2      4  20  209  199   36   4  1\n",
      "3      0   8   49  212  107  25  0\n",
      "4      0   1    0    1    4   0  0\n"
     ]
    }
   ],
   "source": [
    "Ypredicted = np.array([0]*len(valYvector))\n",
    "for i in range(0,len(valXmatrix)):\n",
    "    assigned = False\n",
    "    for j in range(1,len(np.unique(train['quality\"\"\"']))):\n",
    "        if getSigmoid(valXmatrix[i,:],theta,j-1)>(1/7):\n",
    "            Ypredicted[i] = j\n",
    "            assigned = True\n",
    "            break\n",
    "        elif assigned == False:\n",
    "            Ypredicted[i] = 0  \n",
    "conMatrix = pd.crosstab(Ypredicted,valYvector)\n",
    "print(conMatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.48299319727891155\n"
     ]
    }
   ],
   "source": [
    "#conMatrix[0][1]\n",
    "sum1 = 0\n",
    "for i in range(1,5):\n",
    "    for j in range(0,6):\n",
    "        if i==j:\n",
    "            sum1 += conMatrix[i][j] \n",
    "print(\"Accuracy is \"+str(sum1/np.sum(np.sum(conMatrix))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
