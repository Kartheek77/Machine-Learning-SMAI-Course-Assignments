{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ApparelData = pd.read_csv('apparel-trainval.csv',sep=',',index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n",
      "4800\n",
      "4800\n",
      "4800\n",
      "4800\n",
      "4800\n",
      "4800\n",
      "4800\n",
      "4800\n",
      "4800\n"
     ]
    }
   ],
   "source": [
    "UniqueLabels=np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "#DataPerClass = {}\n",
    "DataPerClass = []\n",
    "for i in UniqueLabels:\n",
    "    #DataPerClass[i] = ApparelData.loc[ApparelData['label'] == i]\n",
    "    tempdf = ApparelData.loc[ApparelData['label'] == i]\n",
    "    DataPerClass.append(tempdf.sample(frac = 0.8))\n",
    "    print(len(DataPerClass[i]))#+str(\" for \")+str(i))\n",
    "train = pd.concat(DataPerClass, ignore_index= True)\n",
    "train = train.sample(frac = 1)\n",
    "val = ApparelData.loc[~ApparelData.index.isin(train.index)]\n",
    "val = val.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EncodedLabel = {}\n",
    "EncodedLabel[0]='T-shirt/top'\n",
    "EncodedLabel[1]='Trouser'\n",
    "EncodedLabel[2]='Pullover'\n",
    "EncodedLabel[3]='Dress'\n",
    "EncodedLabel[4]='Coat'\n",
    "EncodedLabel[5]='Sandal'\n",
    "EncodedLabel[6]='Shirt'\n",
    "EncodedLabel[7]='Sneaker'\n",
    "EncodedLabel[8]='Bag'\n",
    "EncodedLabel[9]='Ankle boot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputeLayerSize = 784\n",
    "hiddenLayerSize = 10\n",
    "outputLayerSize = 784\n",
    "#numOfHiddenLayers = 1\n",
    "#initialize weights and biases \n",
    "Weights ={}\n",
    "Biases ={}\n",
    "hiddenLayerSizes1 = [14,14,14]\n",
    "numOfHiddenLayers = len(hiddenLayerSizes1)\n",
    "\n",
    "method = 'Sigmoid'\n",
    "#method = 'Relu'\n",
    "#method = 'tanhx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(hiddenLayerSizes1)):\n",
    "    if(i==0):        \n",
    "        Weights[i] = np.random.randn(hiddenLayerSizes1[i],inputeLayerSize)*np.sqrt(2/inputeLayerSize)\n",
    "        Biases[i] = np.random.randn(hiddenLayerSizes1[i],1)*np.sqrt(2/inputeLayerSize)\n",
    "    else:\n",
    "        Weights[i] = np.random.randn(hiddenLayerSizes1[i],hiddenLayerSizes1[i-1])*np.sqrt(2/hiddenLayerSizes1[i-1])\n",
    "        Biases[i] = np.random.randn(hiddenLayerSizes1[i],1)*np.sqrt(2/hiddenLayerSizes1[i-1])\n",
    "\n",
    "Weights[numOfHiddenLayers] = np.random.randn(outputLayerSize,hiddenLayerSizes1[numOfHiddenLayers-1])*np.sqrt(2/hiddenLayerSizes1[numOfHiddenLayers-1])\n",
    "Biases[numOfHiddenLayers] = np.random.randn(outputLayerSize,1)*np.sqrt(2/hiddenLayerSizes1[numOfHiddenLayers-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Weights:\n",
    "    Weights[i] = 0.01*Weights[i]\n",
    "    Biases[i] = 0.01*Biases[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 784)\n",
      "(14, 14)\n",
      "(14, 14)\n",
      "(784, 14)\n"
     ]
    }
   ],
   "source": [
    "for i in Weights:\n",
    "    print(Weights[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSigmoid(x,method):\n",
    "    if(method == 'Sigmoid'):\n",
    "        x = np.clip(x,-500,500)\n",
    "        return 1/(1+np.exp(-x))        \n",
    "    elif(method == 'Relu'):\n",
    "        #x = np.clip(x,-500,+500)\n",
    "        return np.maximum(x, 0)\n",
    "        #return (abs(x) + x) / 2         \n",
    "    elif(method == 'tanhx'):\n",
    "        return (2*(getSigmoid(2*x,'Sigmoid')))-1\n",
    "    \n",
    "def getSigmoidDash(x,method):\n",
    "    if(method == 'Sigmoid'):\n",
    "        tempDer3 = x.copy()\n",
    "        tempDer3[tempDer3.all()>-500 and tempDer3.all()<500] = 1.0\n",
    "        tempDer3[tempDer3.all()>500 and tempDer3.all()<-500] = 0.0\n",
    "        #tempDer1 = np.array([1.0 if (t.any()>-500 and t.any()<500) else 0.0 for t in x])\n",
    "        #tempDer1 = tempDer1.reshape(x.shape[0],x.shape[1])\n",
    "        tempDer2 = getSigmoid(x,method)*(1-getSigmoid(x,method))\n",
    "        return tempDer2*tempDer3\n",
    "        return getSigmoid(x,method)*(1-getSigmoid(x,method))\n",
    "    elif(method == 'Relu'):\n",
    "        x[x<=0] = 0\n",
    "        x[x>0] = 1.0        \n",
    "        return x\n",
    "    elif(method == 'tanhx'):\n",
    "        return (1 - (getSigmoid(x,'tanhx'))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "(14, 240)\n",
      "(14, 240)\n",
      "(14, 240)\n",
      "(784, 240)\n",
      "(784, 240)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,240) (784,240) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-75b2ddf77047>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mYvectorModified\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mYvector\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mUniqueLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mYhat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mYhat\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mCost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mYvectorModified\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#/batchSize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,240) (784,240) "
     ]
    }
   ],
   "source": [
    "TrainErrorInEachEpoch = []\n",
    "ValErrorInEachEpoch = []\n",
    "numOfIterInEachEpochs = 200\n",
    "batchSize = 240\n",
    "for epoch in range(0,20):\n",
    "    print(\"Epoch is \"+str(epoch))\n",
    "    for j in range(0,numOfIterInEachEpochs):\n",
    "        #print(\"Iteration is \"+str(j))\n",
    "        Xmatrix = train.iloc[0+(j*batchSize):batchSize+(j*batchSize),1:].values    \n",
    "        Yvector = train.iloc[0+(j*batchSize):batchSize+(j*batchSize),0].values\n",
    "        #print(str(0+(j*batchSize))+str(\" - \")+str(batchSize+(j*batchSize)))\n",
    "        #forward pass\n",
    "        z = {}\n",
    "        z[-1] = Xmatrix.T\n",
    "        for i in range(0,numOfHiddenLayers):#np.reshape(a, (3,1))\n",
    "            if(i==0):\n",
    "                z[i] = (Weights[i]@getSigmoid(Xmatrix.T,method))+Biases[i]  \n",
    "                print(z[i].shape)\n",
    "            else:                \n",
    "                #z[i-1] = np.clip( z[i-1], -500, +500 )\n",
    "                #z[i]= (Weights[i]@(1./(1+np.exp(-1*z[i-1]))))+Biases[i]\n",
    "                z[i]= (Weights[i]@getSigmoid(z[i-1],method))+Biases[i]\n",
    "                print(z[i].shape)\n",
    "        \n",
    "        z[numOfHiddenLayers] = (Weights[i]@z[i-1])\n",
    "        Yhat = z[numOfHiddenLayers]\n",
    "        YvectorModified = z[-1]\n",
    "        #YvectorModified = (Yvector[:,None]==UniqueLabels).astype(int).T\n",
    "        #Yhat[Yhat==0] = 1e-10\n",
    "        Cost = np.sum((np.array(Yhat-YvectorModified)**2).sum(axis=0))\n",
    "        #Cost = np.sum(-1*YvectorModified*np.log(Yhat))#/batchSize\n",
    "        \n",
    "        \n",
    "        #if(j==(numOfIterInEachEpochs-1)):\n",
    "        print(Cost)\n",
    "        \n",
    "        #backwardprop\n",
    "        \n",
    "        GradWeights = {}\n",
    "        GradBiases = {}\n",
    "\n",
    "        DcostDAct = {}\n",
    "\n",
    "        DcostDAct[numOfHiddenLayers-1] = ((Weights[numOfHiddenLayers].T)@(Yhat-YvectorModified))\n",
    "        \n",
    "        for temp3 in range(numOfHiddenLayers-2,-1,-1):\n",
    "            DcostDAct[temp3] = (Weights[temp3+1].T)@(getSigmoidDash(z[temp3+1],method)*DcostDAct[temp3+1])                \n",
    "        \n",
    "        GradWeights[numOfHiddenLayers] = (Yhat-YvectorModified)@(getSigmoid(z[numOfHiddenLayers-1].T,method))\n",
    "        GradBiases[numOfHiddenLayers] = (Yhat-YvectorModified).sum(axis=1)\n",
    "        \n",
    "        for temp1 in range(numOfHiddenLayers-1,-1,-1):\n",
    "            GradWeights[temp1] = ((getSigmoidDash(z[temp1],method)*DcostDAct[temp1])@getSigmoid(z[temp1-1].T,method))\n",
    "            GradBiases[temp1] = (getSigmoidDash(z[temp1],method)*DcostDAct[temp1]).sum(axis=1)\n",
    "            \n",
    "        #GradWeights[0] = ((getSigmoidDash(z[0],method)*DcostDAct[0])@(z[-1].T))\n",
    "        #GradBiases[0] = (getSigmoidDash(z[0],method)*DcostDAct[0]).sum(axis=1) \n",
    "      \n",
    "        for item in GradBiases:\n",
    "            GradBiases[item] = GradBiases[item].reshape(GradBiases[item].shape[0],1)\n",
    "          \n",
    "        \n",
    "       \n",
    "        #finding gradients and updating weights and biases      \n",
    "            \n",
    "        for temp6 in Weights:\n",
    "            Weights[temp6] =  Weights[temp6] - (0.0005*GradWeights[temp6])\n",
    "        for temp7 in Biases:\n",
    "            Biases[temp7] = Biases[temp7] - (0.0005*GradBiases[temp7]) #*(1/batchSize)           \n",
    "        \n",
    "    #trainError = getError(train,Weights,Biases,numOfHiddenLayers,'yes')\n",
    "    #valError = getError(val,Weights,Biases,numOfHiddenLayers,'no')\n",
    "    #TrainErrorInEachEpoch.append(trainError)\n",
    "    #ValErrorInEachEpoch.append(valError)\n",
    "    #print(trainError)\n",
    "    #print(valError)\n",
    "    #if(epoch == 14):\n",
    "    #Cost = getLoss(train,Weights,Biases,numOfHiddenLayers)\n",
    "    #print(Cost)\n",
    "    #ValErrorInEachEpoch.append(Cost)\n",
    "     #   CostAtEndOffiftyEpochs[numOfHiddenLayers]=(getLoss(train,Weights,Biases,numOfHiddenLayers))\n",
    "    #if(valError > trainError):\n",
    "     #   break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((Yhat)**2).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((np.array(Yhat-YvectorModified)**2).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 784)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xmatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0m_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\imp.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(name, file, filename, details)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[1;34m(name, path, file)\u001b[0m\n\u001b[0;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m# Protocol buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 74\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-256d845ca6de>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-256d845ca6de>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    conda activate tf_gpu\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "conda activate tf_gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100397\n"
     ]
    }
   ],
   "source": [
    "for i in range(100000 ,100999+1):\n",
    "    if i%9127==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2, 4, 7, 9, 11, 5, 10, 1, 6, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "\n",
    "def is_solution(perm):\n",
    "    for (i1, i2) in it.combinations(range(len(perm)), 2):\n",
    "        if abs(i1 - i2) == abs(perm[i1] - perm[i2]):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "for perm in it.permutations(range(12)):\n",
    "    if is_solution(perm):\n",
    "        print(perm)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n",
      "[2, 3, 4, 5]\n",
      "[3, 4, 5]\n",
      "[4, 5]\n",
      "[5]\n",
      "calculating 4 5\n",
      "calculating 3 9\n",
      "calculating 2 12\n",
      "calculating 1 14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "def findSum(list):\n",
    "    print(list)\n",
    "    if(len(list)==1):\n",
    "        return list[0]\n",
    "    else:\n",
    "        a = list[0]\n",
    "        b = findSum(list[1:])\n",
    "        print(\"calculating \"+str(a)+\" \"+str(b))\n",
    "        return a+b\n",
    "a = [1,2,3,4,5]\n",
    "print(findSum(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
