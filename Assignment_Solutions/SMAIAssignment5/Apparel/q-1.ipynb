{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ApparelData = pd.read_csv('apparel-trainval.csv',sep=',',index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ApparelData.iloc[:,1:] = ApparelData.iloc[:,1:]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n",
      "4800\n",
      "4800\n",
      "4800\n",
      "4800\n",
      "4800\n",
      "4800\n",
      "4800\n",
      "4800\n",
      "4800\n"
     ]
    }
   ],
   "source": [
    "UniqueLabels=np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "#DataPerClass = {}\n",
    "DataPerClass = []\n",
    "for i in UniqueLabels:\n",
    "    #DataPerClass[i] = ApparelData.loc[ApparelData['label'] == i]\n",
    "    tempdf = ApparelData.loc[ApparelData['label'] == i]\n",
    "    DataPerClass.append(tempdf.sample(frac = 0.8))\n",
    "    print(len(DataPerClass[i]))#+str(\" for \")+str(i))\n",
    "train = pd.concat(DataPerClass, ignore_index= True)\n",
    "train = train.sample(frac = 1)\n",
    "val = ApparelData.loc[~ApparelData.index.isin(train.index)]\n",
    "val = val.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.max(np.max(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EncodedLabel = {}\n",
    "EncodedLabel[0]='T-shirt/top'\n",
    "EncodedLabel[1]='Trouser'\n",
    "EncodedLabel[2]='Pullover'\n",
    "EncodedLabel[3]='Dress'\n",
    "EncodedLabel[4]='Coat'\n",
    "EncodedLabel[5]='Sandal'\n",
    "EncodedLabel[6]='Shirt'\n",
    "EncodedLabel[7]='Sneaker'\n",
    "EncodedLabel[8]='Bag'\n",
    "EncodedLabel[9]='Ankle boot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputeLayerSize = 784\n",
    "hiddenLayerSize = 10\n",
    "outputLayerSize = 10\n",
    "numOfHiddenLayers = 5\n",
    "#initialize weights and biases \n",
    "Weights ={}\n",
    "Biases ={}\n",
    "hiddenLayerSizes1 = [10,10]\n",
    "numOfHiddenLayers = len(hiddenLayerSizes1)\n",
    "\n",
    "#method = 'Sigmoid'\n",
    "#method = 'Relu'\n",
    "method = 'tanhx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(hiddenLayerSizes1)):\n",
    "    if(i==0):        \n",
    "        Weights[i] = np.random.randn(hiddenLayerSizes1[i],inputeLayerSize)*np.sqrt(2/inputeLayerSize)\n",
    "        Biases[i] = np.random.randn(hiddenLayerSizes1[i],1)*np.sqrt(2/inputeLayerSize)\n",
    "    else:\n",
    "        Weights[i] = np.random.randn(hiddenLayerSizes1[i],hiddenLayerSizes1[i-1])*np.sqrt(2/hiddenLayerSizes1[i-1])\n",
    "        Biases[i] = np.random.randn(hiddenLayerSizes1[i],1)*np.sqrt(2/hiddenLayerSizes1[i-1])\n",
    "\n",
    "Weights[numOfHiddenLayers] = np.random.randn(outputLayerSize,hiddenLayerSizes1[numOfHiddenLayers-1])*np.sqrt(2/hiddenLayerSizes1[numOfHiddenLayers-1])\n",
    "Biases[numOfHiddenLayers] = np.random.randn(outputLayerSize,1)*np.sqrt(2/hiddenLayerSizes1[numOfHiddenLayers-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InitializedWeights = Weights.copy()\n",
    "InitializedBiases = Biases.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights = InitializedWeights\n",
    "Biases = InitializedBiases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in Weights:\n",
    "    Weights[i] = 0.01*Weights[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSigmoid(x,method):\n",
    "    if(method == 'Sigmoid'):\n",
    "        x = np.clip(x,-500,500)\n",
    "        return 1/(1+np.exp(-x))        \n",
    "    elif(method == 'Relu'):\n",
    "        #x = np.clip(x,-500,+500)\n",
    "        return np.maximum(x, 0)\n",
    "        #return (abs(x) + x) / 2         \n",
    "    elif(method == 'tanhx'):\n",
    "        return (2*(getSigmoid(2*x,'Sigmoid')))-1\n",
    "    \n",
    "def getSigmoidDash(x,method):\n",
    "    if(method == 'Sigmoid'):\n",
    "        tempDer3 = x.copy()\n",
    "        tempDer3[tempDer3.all()>-500 and tempDer3.all()<500] = 1.0\n",
    "        tempDer3[tempDer3.all()>500 and tempDer3.all()<-500] = 0.0\n",
    "        #tempDer1 = np.array([1.0 if (t.any()>-500 and t.any()<500) else 0.0 for t in x])\n",
    "        #tempDer1 = tempDer1.reshape(x.shape[0],x.shape[1])\n",
    "        tempDer2 = getSigmoid(x,method)*(1-getSigmoid(x,method))\n",
    "        return tempDer2*tempDer3\n",
    "        return getSigmoid(x,method)*(1-getSigmoid(x,method))\n",
    "    elif(method == 'Relu'):\n",
    "        x[x<=0] = 0\n",
    "        x[x>0] = 1.0        \n",
    "        return x\n",
    "    elif(method == 'tanhx'):\n",
    "        return (1 - (getSigmoid(x,'tanhx'))**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickle_in = open(\"Weights.pickle\",\"rb\")\n",
    "Weights = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLoss(givenData,Weights,Biases,numOfHiddenLayers):\n",
    "    Xmatrix1 = givenData.iloc[:,1:].values\n",
    "    z1 = {}\n",
    "    for i in range(0,numOfHiddenLayers+1):#np.reshape(a, (3,1))\n",
    "        if(i==0):\n",
    "            z1[i] = (Weights[i]@getSigmoid(Xmatrix1.T,method))+Biases[i]   \n",
    "        else:\n",
    "            z1[i]= (Weights[i]@getSigmoid(z1[i-1],method))+Biases[i]\n",
    "    z1[numOfHiddenLayers] = np.clip(z1[numOfHiddenLayers],-500,500)\n",
    "    Yhat1 = (np.exp(z1[numOfHiddenLayers]))/(np.sum(np.exp(z1[numOfHiddenLayers]), axis=0)[None,:])\n",
    "    valYvector1 = givenData.iloc[:,0].values\n",
    "    UniqueLabels=np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "    #creating indicator vectors\n",
    "    YvectorModified1 = (valYvector1[:,None]==UniqueLabels).astype(int).T\n",
    "    Yhat1[Yhat1==0] = 1e-10\n",
    "    Cost = np.sum(-1*YvectorModified1*np.log(Yhat1))#/batchSize\n",
    "    return Cost    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getError(givenData,Weights,Biases,numOfHiddenLayers,istrain):\n",
    "    Xmatrix1 = givenData.iloc[:,1:].values\n",
    "    z1 = {}\n",
    "    for i in range(0,numOfHiddenLayers+1):#np.reshape(a, (3,1))\n",
    "        if(i==0):\n",
    "            z1[i] = (Weights[i]@getSigmoid(Xmatrix1.T,method))+Biases[i]   \n",
    "        else:\n",
    "            z1[i]= (Weights[i]@getSigmoid(z1[i-1],method))+Biases[i]\n",
    "    z1[numOfHiddenLayers] = np.clip(z1[numOfHiddenLayers],-500,500)\n",
    "    Yhat1 = (np.exp(z1[numOfHiddenLayers]))/(np.sum(np.exp(z1[numOfHiddenLayers]), axis=0)[None,:])\n",
    "    valYvector1 = givenData.iloc[:,0].values\n",
    "    \n",
    "    \n",
    "    if(istrain == 'yes'):\n",
    "        UniqueLabels=np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "        #creating indicator vectors\n",
    "        YvectorModified1 = (valYvector1[:,None]==UniqueLabels).astype(int).T\n",
    "        Yhat1[Yhat1==0] = 1e-10\n",
    "        Cost = np.sum(-1*YvectorModified1*np.log(Yhat1))#/batchSize\n",
    "        print(Cost)\n",
    "        \n",
    "    \n",
    "    PredictedLabelsForTest1 = np.argmax(Yhat1, axis=0) \n",
    "    conMatrix = pd.crosstab(valYvector1,PredictedLabelsForTest1)\n",
    "    sum1 = 0\n",
    "    for temp25 in np.unique(valYvector1):\n",
    "        for temp26 in np.unique(PredictedLabelsForTest1):\n",
    "            if temp25==temp26:\n",
    "                sum1 += conMatrix[temp25][temp26] \n",
    "    Accuracy = (sum1/np.sum(np.sum(conMatrix)))\n",
    "    return (1-Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CostAtEndOffiftyEpochs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "Epoch is 1\n",
      "Epoch is 2\n",
      "Epoch is 3\n",
      "Epoch is 4\n",
      "Epoch is 5\n",
      "Epoch is 6\n",
      "Epoch is 7\n",
      "Epoch is 8\n",
      "Epoch is 9\n",
      "Epoch is 10\n",
      "Epoch is 11\n",
      "Epoch is 12\n",
      "Epoch is 13\n",
      "Epoch is 14\n"
     ]
    }
   ],
   "source": [
    "TrainErrorInEachEpoch = []\n",
    "ValErrorInEachEpoch = []\n",
    "numOfIterInEachEpochs = 200\n",
    "batchSize = 240\n",
    "for epoch in range(0,15):\n",
    "    print(\"Epoch is \"+str(epoch))\n",
    "    for j in range(0,numOfIterInEachEpochs):\n",
    "        #print(\"Iteration is \"+str(j))\n",
    "        Xmatrix = train.iloc[0+(j*batchSize):batchSize+(j*batchSize),1:].values    \n",
    "        Yvector = train.iloc[0+(j*batchSize):batchSize+(j*batchSize),0].values\n",
    "        #print(str(0+(j*batchSize))+str(\" - \")+str(batchSize+(j*batchSize)))\n",
    "        #forward pass\n",
    "        z = {}\n",
    "        z[-1] = Xmatrix.T\n",
    "        for i in range(0,numOfHiddenLayers+1):#np.reshape(a, (3,1))\n",
    "            if(i==0):\n",
    "                z[i] = (Weights[i]@getSigmoid(Xmatrix.T,method))+Biases[i]        \n",
    "            else:                \n",
    "                #z[i-1] = np.clip( z[i-1], -500, +500 )\n",
    "                #z[i]= (Weights[i]@(1./(1+np.exp(-1*z[i-1]))))+Biases[i]\n",
    "                z[i]= (Weights[i]@getSigmoid(z[i-1],method))+Biases[i]\n",
    "                \n",
    "        z[numOfHiddenLayers] = np.clip(z[numOfHiddenLayers],-500,+500)\n",
    "        Yhat = (np.exp(z[numOfHiddenLayers]))/(np.sum(np.exp(z[numOfHiddenLayers]), axis=0)[None,:])\n",
    "        UniqueLabels=np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "        #creating indicator vectors\n",
    "        YvectorModified = (Yvector[:,None]==UniqueLabels).astype(int).T\n",
    "        #Yhat[Yhat==0] = 1e-10\n",
    "        #Cost = np.sum(-1*YvectorModified*np.log(Yhat))#/batchSize\n",
    "        \n",
    "        #if(j==(numOfIterInEachEpochs-1)):\n",
    "        #print(Cost)\n",
    "        \n",
    "        #backwardprop\n",
    "        \n",
    "        GradWeights = {}\n",
    "        GradBiases = {}\n",
    "\n",
    "        DcostDAct = {}\n",
    "\n",
    "        DcostDAct[numOfHiddenLayers-1] = ((Weights[numOfHiddenLayers].T)@(Yhat-YvectorModified))\n",
    "        \n",
    "        for temp3 in range(numOfHiddenLayers-2,-1,-1):\n",
    "            DcostDAct[temp3] = (Weights[temp3+1].T)@(getSigmoidDash(z[temp3+1],method)*DcostDAct[temp3+1])                \n",
    "        \n",
    "        GradWeights[numOfHiddenLayers] = (Yhat-YvectorModified)@(getSigmoid(z[numOfHiddenLayers-1].T,method))\n",
    "        GradBiases[numOfHiddenLayers] = (Yhat-YvectorModified).sum(axis=1)\n",
    "        \n",
    "        for temp1 in range(numOfHiddenLayers-1,-1,-1):\n",
    "            GradWeights[temp1] = ((getSigmoidDash(z[temp1],method)*DcostDAct[temp1])@getSigmoid(z[temp1-1].T,method))\n",
    "            GradBiases[temp1] = (getSigmoidDash(z[temp1],method)*DcostDAct[temp1]).sum(axis=1)\n",
    "            \n",
    "        #GradWeights[0] = ((getSigmoidDash(z[0],method)*DcostDAct[0])@(z[-1].T))\n",
    "        #GradBiases[0] = (getSigmoidDash(z[0],method)*DcostDAct[0]).sum(axis=1) \n",
    "      \n",
    "        for item in GradBiases:\n",
    "            GradBiases[item] = GradBiases[item].reshape(GradBiases[item].shape[0],1)\n",
    "          \n",
    "        \n",
    "       \n",
    "        #finding gradients and updating weights and biases      \n",
    "            \n",
    "        for temp6 in Weights:\n",
    "            Weights[temp6] =  Weights[temp6] - (0.0005*GradWeights[temp6])\n",
    "        for temp7 in Biases:\n",
    "            Biases[temp7] = Biases[temp7] - (0.0005*GradBiases[temp7]) #*(1/batchSize)           \n",
    "        \n",
    "    #trainError = getError(train,Weights,Biases,numOfHiddenLayers,'yes')\n",
    "    #valError = getError(val,Weights,Biases,numOfHiddenLayers,'no')\n",
    "    #TrainErrorInEachEpoch.append(trainError)\n",
    "    #ValErrorInEachEpoch.append(valError)\n",
    "    #print(trainError)\n",
    "    #print(valError)\n",
    "    if(epoch == 14):\n",
    "        CostAtEndOffiftyEpochs[numOfHiddenLayers]=(getLoss(train,Weights,Biases,numOfHiddenLayers))\n",
    "    #if(valError > trainError):\n",
    "     #   break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 20615.430462369783, 2: 21454.481810745216}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CostAtEndOffiftyEpochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"WeightsRelu.pickle\",\"wb\")\n",
    "pickle.dump(Weights, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>81</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1185</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>827</td>\n",
       "      <td>11</td>\n",
       "      <td>359</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>1039</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>37</td>\n",
       "      <td>1091</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1091</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>245</td>\n",
       "      <td>10</td>\n",
       "      <td>132</td>\n",
       "      <td>47</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1159</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>4</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0     1    2     3     4     5    6     7     8     9\n",
       "row_0                                                          \n",
       "0      1006     6   31    81    11     0   40     0    24     0\n",
       "1         0  1185    4    19     3     0    0     0     2     0\n",
       "2        12     3  827    11   359     0   12     0     8     0\n",
       "3        29    26   18  1039    85     0    2     0     4     0\n",
       "4         1     5   70    37  1091     0    8     0     3     0\n",
       "5         0     1    0     1     0  1091    0    61     3     8\n",
       "6       245    10  132    47   327     0  377     0    29     0\n",
       "7         0     0    0     0     0    16    0  1159     1    11\n",
       "8         3     2    3     5     4     6    6     8  1175     0\n",
       "9         0     1    0     1     0    18    0   153     4  1030"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Xmatrix1 = ApparelTestData.values\n",
    "Xmatrix1 = val.iloc[:,1:].values\n",
    "z1 = {}\n",
    "for i in range(0,numOfHiddenLayers+1):#np.reshape(a, (3,1))\n",
    "    if(i==0):\n",
    "        z1[i] = (Weights[i]@getSigmoid(Xmatrix1.T,method))+Biases[i]   \n",
    "    else:\n",
    "        z1[i]= (Weights[i]@getSigmoid(z1[i-1],method))+Biases[i]\n",
    "        #print(i)\n",
    "        #print(z[i].shape)\n",
    "#finding outputs using softmax\n",
    "#z1[-1] = Xmatrix1.T\n",
    "z1[numOfHiddenLayers] = np.clip(z1[numOfHiddenLayers],-500,500)\n",
    "Yhat1 = (np.exp(z1[numOfHiddenLayers]))/(np.sum(np.exp(z1[numOfHiddenLayers]), axis=0)[None,:])\n",
    "valYvector = val.iloc[:,0].values\n",
    "PredictedLabelsForTest = np.argmax(Yhat1, axis=0) \n",
    "print(np.unique(PredictedLabelsForTest))\n",
    "conMatrix = pd.crosstab(valYvector,PredictedLabelsForTest)\n",
    "conMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ApparelTestData = pd.read_csv('apparel-test.csv',sep=',',index_col = False)\n",
    "Xmatrix1 = ApparelTestData.values\n",
    "z1 = {}\n",
    "for i in range(0,numOfHiddenLayers+1):#np.reshape(a, (3,1))\n",
    "    if(i==0):\n",
    "        z1[i] = (Weights[i]@getSigmoid(Xmatrix1.T,method))+Biases[i]   \n",
    "    else:\n",
    "        #if method == sigmoid:\n",
    "        #z1[i-1] = np.clip( z1[i-1], -500, 500 )\n",
    "        z1[i]= (Weights[i]@getSigmoid(z1[i-1],method))+Biases[i]\n",
    "        #print(i)\n",
    "        #print(z[i].shape)\n",
    "#finding outputs using softmax\n",
    "#z1[-1] = Xmatrix1.T\n",
    "#z1[numOfHiddenLayers] = np.clip(z1[numOfHiddenLayers],-500,500)\n",
    "Yhat1 = (np.exp(z1[numOfHiddenLayers]))/(np.sum(np.exp(z1[numOfHiddenLayers]), axis=0)[None,:])\n",
    "PredictedLabelsForTest = np.argmax(Yhat1, axis=0) \n",
    "ApparelTestData.insert(loc=0, column='labels', value=PredictedLabelsForTest)\n",
    "import matplotlib.pyplot as plt\n",
    "for index, row in ApparelTestData.iterrows():#.loc[0:20,:]\n",
    "    #for j in ApparelDataSample.columns:\n",
    "    label = row[0]\n",
    "    pixels = row[1:]\n",
    "    # Make those columns into a array of 8-bits pixels\n",
    "    # This array will be of 1D with length 784\n",
    "    # The pixel intensity values are integers from 0 to 255\n",
    "    pixels = np.array(pixels, dtype='uint8')\n",
    "    # Reshape the array into 28 x 28 array (2-dimensional array)\n",
    "    pixels = pixels.reshape((28,28))\n",
    "    plt.title('figure show below is {label}'.format(label=EncodedLabel[label]+str(label)))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.show()\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(ApparelTestData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReluTrainErrorInEachEpoch = TrainErrorInEachEpoch.copy()\n",
    "ReluValErrorInEachEpoch = ValErrorInEachEpoch.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SigmoidTrainErrorInEachEpoch = TrainErrorInEachEpoch.copy()\n",
    "SigmoidValErrorInEachEpoch = ValErrorInEachEpoch.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tanhxTrainErrorInEachEpoch = TrainErrorInEachEpoch.copy()\n",
    "tanhxValErrorInEachEpoch = ValErrorInEachEpoch.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots()\n",
    "#for i in enumerate(thresholdValues):\n",
    "#TrainErrorInEachEpoch\n",
    "#ValErrorInEachEpoch\n",
    "#ax.plot(range(0,len(ReluTrainErrorInEachEpoch[:])),ReluTrainErrorInEachEpoch[:], label='trainError Relu')\n",
    "ax.plot(range(0,len(tanhxTrainErrorInEachEpoch[:])),tanhxTrainErrorInEachEpoch[:], label='trainError tanhx')\n",
    "#ax.plot(range(0,len(SigmoidTrainErrorInEachEpoch[:])),SigmoidTrainErrorInEachEpoch[:], label='trainError Sigmoid')\n",
    "#ax.plot(range(0,len(ReluValErrorInEachEpoch[:])),ReluValErrorInEachEpoch[:], label='valError Relu')\n",
    "ax.plot(range(0,len(tanhxValErrorInEachEpoch[:])),tanhxValErrorInEachEpoch[:], label='valError tanhx')\n",
    "#ax.plot(range(0,len(SigmoidValErrorInEachEpoch[:])),SigmoidValErrorInEachEpoch[:], label='ValError Sigmoid')\n",
    "ax.legend(loc=1) # upper left corner\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Val Error vs Epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots()\n",
    "#for i in enumerate(thresholdValues):\n",
    "#TrainErrorInEachEpoch\n",
    "#ValErrorInEachEpoch\n",
    "ax.plot(range(0,len(TrainErrorInEachEpoch[:])),TrainErrorInEachEpoch[:], label='TrainError')\n",
    "ax.plot(range(0,len(ValErrorInEachEpoch[:])),ValErrorInEachEpoch[:], label='ValError')\n",
    "ax.legend(loc=1) # upper left corner\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Epoch vs TrainVal Error');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots()\n",
    "#for i in enumerate(thresholdValues):\n",
    "#TrainErrorInEachEpoch\n",
    "#ValErrorInEachEpoch\n",
    "ax.plot(range(0,len(TrainErrorInEachEpoch[:])),TrainErrorInEachEpoch[:], label='TrainError')\n",
    "ax.plot(range(0,len(ValErrorInEachEpoch[:])),ValErrorInEachEpoch[:], label='ValError')\n",
    "ax.legend(loc=1) # upper left corner\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Epoch vs TrainVal Error');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots()\n",
    "#for i in enumerate(thresholdValues):\n",
    "#TrainErrorInEachEpoch\n",
    "#ValErrorInEachEpoch\n",
    "ax.plot(range(0,len(TrainErrorInEachEpoch[40:])),TrainErrorInEachEpoch[40:], label='TrainError')\n",
    "ax.plot(range(0,len(ValErrorInEachEpoch[40:])),ValErrorInEachEpoch[40:], label='ValError')\n",
    "ax.legend(loc=3) # upper left corner\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Epoch vs TrainVal Error');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " print('shape of Biases after update')    \n",
    "        for item in Biases:\n",
    "            print(Biases[item].shape)\n",
    "   print('shape of Biases before update')    \n",
    "        for item in Biases:\n",
    "            print(Biases[item].shape)\n",
    "\n",
    "  \n",
    "        print('shape of GradBiases')\n",
    "        for item in GradBiases:\n",
    "            print(GradBiases[item].shape)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A=np.array([[1,2],[3,4]])\n",
    "A[A.any()>=2 and A.any()<=3] = 999\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ApparelTestData = pd.read_csv('apparel-test.csv',sep=',',index_col = False)\n",
    "Xmatrix1 = ApparelTestData.values\n",
    "z1 = {}\n",
    "for i in range(0,numOfHiddenLayers+1):#np.reshape(a, (3,1))\n",
    "    if(i==0):\n",
    "        z1[i] = (Weights[i]@getSigmoid(Xmatrix1.T,method))+Biases[i]   \n",
    "    else:\n",
    "        #if method == sigmoid:\n",
    "        #z1[i-1] = np.clip( z1[i-1], -500, 500 )\n",
    "        z1[i]= (Weights[i]@getSigmoid(z1[i-1],method))+Biases[i]\n",
    "        #print(i)\n",
    "        #print(z[i].shape)\n",
    "#finding outputs using softmax\n",
    "#z1[-1] = Xmatrix1.T\n",
    "#z1[numOfHiddenLayers] = np.clip(z1[numOfHiddenLayers],-500,500)\n",
    "Yhat1 = (np.exp(z1[numOfHiddenLayers]))/(np.sum(np.exp(z1[numOfHiddenLayers]), axis=0)[None,:])\n",
    "PredictedLabelsForTest = np.argmax(Yhat1, axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "orig_stdout = sys.stdout\n",
    "f = open('2018801010_prediction1.csv', 'w')\n",
    "sys.stdout = f\n",
    "for i in PredictedLabelsForTest:\n",
    "    print(i)\n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
