{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMAI (CSE 471)\n",
    "Spring-2019\n",
    "Assignment-1\n",
    "Name: Karnati Venkata Kartheek\n",
    "Roll Number 2018801010\n",
    "\n",
    "Part 1\n",
    "---------\n",
    "Train decision tree only on categorical data. Report precision, recall, f1 score and accuracy.\n",
    "\n",
    "Algorithm implementation\n",
    "\n",
    "In the categorical data each attribute have some limited set of values. From the given data the tree is constructed such that at each node a decision is made (Like if a categorical attribute is equal to a particular value? or if a numerical attribute is less than particular value). By taking a decision samples are divided into two parts. If decision attribute is categorical attribute then one part is with categorical attribute having particular value and other with categorical attribute not equal to that that particular value. If decision attribute is numerical attribute then one part is with that numerical attribute having values less than decision attribute value and other part is with values having more than that decision attribute value.\n",
    "\n",
    "Here impurity measuring functions such as Gini Index, Misclassification rate and entropy, gives us which decision is best so that mixing of positive and negative labels is minimized. If for a particular decision the weighted average of impurity of two parts of data is less than those of all others(decisions) then that particular decision is the best decision. \n",
    "        \n",
    "Here In the code a recursive function takes in all the samples of data and calls the function that calculates the Best Attribute at that node which returns the Best Attribute Along with its value. On obtaining the Best Attribute a node is created to represent that attribute and function is called recursively to create two child nodes for this node, giving input the two groups of samples that are formed at this node. Recursive function is terminated when all the samples have labels positive or all have labels negative or less than a minimum number of samples in each nodes or impurity of current samples becomes less than a particular value.\n",
    "Given data is split into two groups. Training data and validation data. A random number generator is used to assign random numbers between 0 and 1 to each row of given data. A row a selected for training data if its less than 0.8. As random number generator is mostly uniform distribution, the proportion of labels is preserved in both training and validation data. \n",
    "\n",
    "Result for part 1:\n",
    "Using Entropy as impurity criteria\n",
    "________________________________________\n",
    "True Positive are    405\n",
    "True Negatives are   888\n",
    "False Positive are   839\n",
    "False Negatives are  117\n",
    "Precsion is          0.32556270096463025\n",
    "Recall is            0.7758620689655172\n",
    "F1_Score is          8.720987654320988\n",
    "Accuracy is          0.5749221876389506\n",
    "_________________________________________\n",
    "( Here 1's  are positive 0's are negative)\n",
    "\t\n",
    "Part2\n",
    "---------\n",
    "Algorithm implementation\n",
    "\tCode is mostly similar to categorical case except here numerical part is involved.\n",
    "Results for part2:\n",
    "\n",
    "Results On Validation Data\n",
    "Using Gini Coefficient as impurity measure\n",
    "___________________________________________\n",
    "True Positive are    495\n",
    "True Negatives are   1699\n",
    "False Positive are   28\n",
    "False Negatives are  27\n",
    "Precsion is          0.9464627151051626\n",
    "Recall is            0.9482758620689655\n",
    "F1_Score is          4.222222222222221\n",
    "Accuracy is          0.9755446865273455\n",
    "___________________________________________\n",
    "( Here 1's  are positive 0's are negative)\n",
    "\n",
    "Results On Validation Data\n",
    "Using Entropy as impurity measure\n",
    "__________________________________________\n",
    "True Positive are    496\n",
    "True Negatives are   1701\n",
    "False Positive are   26\n",
    "False Negatives are  26\n",
    "Precsion is          0.9501915708812261\n",
    "Recall is            0.9501915708812261\n",
    "F1_Score is          4.209677419354839\n",
    "Accuracy is          0.976878612716763\n",
    "___________________________________________\n",
    "( Here 1's  are positive 0's are negative)\n",
    "\n",
    "Results On Validation Data\n",
    "Using MissClassification Rate as impurity measure\n",
    "__________________________________________________\n",
    "True Positive are    497\n",
    "True Negatives are   1689\n",
    "False Positive are   38\n",
    "False Negatives are  25\n",
    "Precsion is          0.9289719626168225\n",
    "Recall is            0.9521072796934866\n",
    "F1_Score is          4.253521126760564\n",
    "Accuracy is          0.9719875500222321\n",
    "__________________________________________________\n",
    "( Here 1's  are positive 0's are negative)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
