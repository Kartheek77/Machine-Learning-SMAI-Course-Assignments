{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating Impurities please wait\n",
      "Decision attribute type is categoricaldecisionAttribute is sales decisionAttributeValue is sales of level 0 number of examples of this node 22\n",
      "Type4\n",
      "Decision attribute type is leafNodedecisionAttribute is leafNode decisionAttributeValue is Positive of level 1 number of examples of this node 3\n",
      "calculating Impurities please wait\n",
      "Decision attribute type is categoricaldecisionAttribute is promotion_last_5years decisionAttributeValue is 0 of level 1 number of examples of this node 19\n",
      "Type4\n",
      "Decision attribute type is leafNodedecisionAttribute is leafNode decisionAttributeValue is Positive of level 2 number of examples of this node 6\n",
      "calculating Impurities please wait\n",
      "Decision attribute type is categoricaldecisionAttribute is sales decisionAttributeValue is IT of level 2 number of examples of this node 13\n",
      "Type4\n",
      "Decision attribute type is leafNodedecisionAttribute is leafNode decisionAttributeValue is Positive of level 3 number of examples of this node 2\n",
      "calculating Impurities please wait\n",
      "Decision attribute type is categoricaldecisionAttribute is sales decisionAttributeValue is management of level 3 number of examples of this node 11\n",
      "Type4\n",
      "Decision attribute type is leafNodedecisionAttribute is leafNode decisionAttributeValue is Positive of level 4 number of examples of this node 2\n",
      "Decision attribute type is leafNodedecisionAttribute is leafNode decisionAttributeValue is Negative of level 4 number of examples of this node 9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "#data = pd.read_csv(\"train.csv\") \n",
    "#ran = np.random.rand(len(data)) < 0.8\n",
    "#train = data[ran]\n",
    "#val = data[~ran]\n",
    "#train.to_csv('UsedTrainingData.csv')\n",
    "#val.to_csv('UsedValidationData.csv')\n",
    "\n",
    "train =  pd.read_csv('UsedTrainingData.csv')\n",
    "val = pd.read_csv('UsedValidationData.csv')\n",
    "\n",
    "train = train.loc[:,['Work_accident', 'promotion_last_5years', 'sales', 'salary','left'] ] \n",
    "val = val.loc[:,['Work_accident', 'promotion_last_5years', 'sales', 'salary','left'] ] \n",
    "\n",
    "train = train.drop_duplicates(subset=None, keep=False, inplace=False)\n",
    "#val = val.drop_duplicates(subset=None, keep=False, inplace=False)\n",
    "\n",
    "targetAttribute = 'left'\n",
    "Attributes = list(train.columns)\n",
    "Attributes.remove(targetAttribute)\n",
    "examples = list(train.index.values) \n",
    "\n",
    "NumericalAttributes = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'time_spend_company']\n",
    "CategoricalAttributes = ['Work_accident', 'promotion_last_5years', 'sales', 'salary']\n",
    "\n",
    "def getImpurityOfExamples(examplesForCurNode,method):\n",
    "    NumberOfPosEx = 0\n",
    "    NumberOfNegEx = 0\n",
    "    for j in examplesForCurNode:\n",
    "        if  str(train.at[int(j),targetAttribute]) == str(1):\n",
    "            NumberOfPosEx = NumberOfPosEx+1\n",
    "        elif str(train.at[int(j),targetAttribute]) == str(0):\n",
    "             NumberOfNegEx = NumberOfNegEx+1\n",
    "    PropOfPos =  NumberOfPosEx/len(examplesForCurNode)\n",
    "    PropOfNeg = NumberOfNegEx/len(examplesForCurNode)\n",
    "    if method == 'Gini':\n",
    "        return (2*PropOfPos*PropOfNeg)\n",
    "    elif method == 'misClasifi':\n",
    "        return min(PropOfPos,PropOfNeg)\n",
    "    elif method == 'Entropy':\n",
    "        if PropOfPos == 0:\n",
    "            return (-1*PropOfNeg*(np.log(PropOfNeg)/np.log(2)))\n",
    "        elif PropOfNeg == 0:\n",
    "            return (-1*PropOfPos*(np.log(PropOfPos)/np.log(2)))\n",
    "        else:\n",
    "            return ((-1*PropOfPos*(np.log(PropOfPos)/np.log(2))) + (-1*PropOfNeg*(np.log(PropOfNeg)/np.log(2))))\n",
    "\n",
    "def getMethodImpurity(Attribute,value,examplesForCurAttr,method): \n",
    "    fra1 = train.loc[examplesForCurAttr,:]\n",
    "    LessThanExamples = []\n",
    "    MoreThanExamples = []\n",
    "    if Attribute in NumericalAttributes: \n",
    "        for j in examplesForCurAttr:\n",
    "            if  float(str(fra1.at[int(j),Attribute])) <= float(str(value)):\n",
    "                LessThanExamples.append(int(j))\n",
    "            else:\n",
    "                MoreThanExamples.append(int(j))\n",
    "    else:\n",
    "        for j in examplesForCurAttr:\n",
    "            if  str(fra1.at[int(j),Attribute]) == str(value):\n",
    "                LessThanExamples.append(int(j))\n",
    "            else:\n",
    "                MoreThanExamples.append(int(j))\n",
    "        if len(MoreThanExamples) <= 0:\n",
    "            return 999\n",
    "        elif len(LessThanExamples) <=0:\n",
    "            return getImpurityOfExamples(MoreThanExamples,method)\n",
    "        else:            \n",
    "            return ((len(LessThanExamples)*getImpurityOfExamples(LessThanExamples,method))+(len(MoreThanExamples)*getImpurityOfExamples(MoreThanExamples,method)))/len(examplesForCurAttr)\n",
    "    \n",
    "class Node(object):\n",
    "    def __init__(self,examples,decisionAttributeType,decisionAttribute,decisionAttributeValue,level):\n",
    "        self.examples = examples\n",
    "        self.decisionAttributeType = decisionAttributeType\n",
    "        self.decisionAttribute = decisionAttribute        \n",
    "        self.decisionAttributeValue = decisionAttributeValue\n",
    "        self.level = level\n",
    "        self.leftChild = None\n",
    "        self.rightChild = None\n",
    "        \n",
    "    def __str__(self): \n",
    "        return \"Decision attribute type is \"+self.decisionAttributeType+\"decisionAttribute is \"+ self.decisionAttribute+\" decisionAttributeValue is \"+ str(self.decisionAttributeValue)+\" of level \"+str(self.level)+\" number of examples of this node \"+str(len(self.examples))\n",
    "    \n",
    "def BestOfAttributes(examplesForCurAttr,targetAttribute,method):\n",
    "    \n",
    "    fra1 = train.loc[examplesForCurAttr,CategoricalAttributes]\n",
    "    dictForCategAttrUniqueValues = {}\n",
    "    for i in CategoricalAttributes:\n",
    "        dictForCategAttrUniqueValues[i] = list(fra1[i].sort_values().unique())\n",
    "    dictForEntropyUniqueValueCateg = copy.deepcopy(dictForCategAttrUniqueValues)\n",
    "    print(\"calculating Impurities please wait\")\n",
    "    for i in CategoricalAttributes:\n",
    "        for j,val in enumerate(dictForCategAttrUniqueValues[i]):\n",
    "            dictForEntropyUniqueValueCateg[i][j] = getMethodImpurity(i,dictForCategAttrUniqueValues[i][j],examplesForCurAttr,method)          \n",
    "    EntropyValuesForCategoricalAttributes = {}\n",
    "    for i in CategoricalAttributes:\n",
    "        EntropyValuesForCategoricalAttributes[i]=min(dictForEntropyUniqueValueCateg[i])\n",
    "    BestOfCategoricalAttributes = min(EntropyValuesForCategoricalAttributes, key=EntropyValuesForCategoricalAttributes.get)\n",
    "    BestOfCategoricalAttributesValue = min(EntropyValuesForCategoricalAttributes.values())   \n",
    "    \n",
    "    if BestOfCategoricalAttributesValue > 1:\n",
    "        return BestOfCategoricalAttributes,'No Attribute'\n",
    "        \n",
    "    for index, item in enumerate(dictForEntropyUniqueValueCateg[BestOfCategoricalAttributes]):\n",
    "        if item == BestOfCategoricalAttributesValue:\n",
    "            BestSplitValueCategorical = dictForCategAttrUniqueValues[BestOfCategoricalAttributes][index]\n",
    "            break            \n",
    "    return BestOfCategoricalAttributes,BestSplitValueCategorical\n",
    "    \n",
    "def DecisionTreeBuilder(examplesForCurNode,targetAttribute,level,method):\n",
    "    allExPos = True\n",
    "    for i in examplesForCurNode:\n",
    "        if str(train.at[int(i),targetAttribute]) == str(1):\n",
    "            pass\n",
    "        else:\n",
    "            allExPos = False\n",
    "            break\n",
    "    if allExPos:        \n",
    "        r = Node(examplesForCurNode,'leafNode','leafNode','Positive',level)\n",
    "        print(r)\n",
    "        #print(\"Type1\")\n",
    "        return r\n",
    "    allExNeg = True\n",
    "    for j in examplesForCurNode:\n",
    "        if str(train.at[j,targetAttribute]) == str(0):\n",
    "            pass\n",
    "        else:\n",
    "            allExNeg = False\n",
    "            break\n",
    "    if allExNeg:\n",
    "        r = Node(examplesForCurNode,'leafNode','leafNode','Negative',level)\n",
    "        print(r)\n",
    "        #print(\"Type2\")\n",
    "        return r\n",
    "    if getImpurityOfExamples(examplesForCurNode,method) < 0.001 or len(examplesForCurNode)<10:\n",
    "        fra1 = train.loc[examplesForCurNode,[targetAttribute] ]\n",
    "        targetAttributesList = fra1[targetAttribute].values\n",
    "        unique1, counts1 = np.unique(targetAttributesList, return_counts=True)\n",
    "        dictOfTaAttr = dict(zip(unique1, counts1))\n",
    "        posCount = dictOfTaAttr[1]\n",
    "        negCount = dictOfTaAttr[0]\n",
    "        if (posCount/(posCount+negCount))>0.24:\n",
    "            r = Node(examplesForCurNode,'leafNode','leafNode','Positive',level)\n",
    "            #numberOfNodes  = numberOfNodes + 1\n",
    "        else:\n",
    "            r = Node(examplesForCurNode,'leafNode','leafNode','Negative',level)\n",
    "            #numberOfNodes  = numberOfNodes + 1\n",
    "        print(r)\n",
    "        #print(\"Type3\")\n",
    "        return r\n",
    "    \n",
    "    BestAttribute,BestAttributeValue = BestOfAttributes(examplesForCurNode,targetAttribute,method)\n",
    "    \n",
    "    if BestAttributeValue == 'No Attribute':\n",
    "        fra1 = train.loc[examplesForCurNode,[targetAttribute] ]\n",
    "        targetAttributesList = fra1[targetAttribute].values\n",
    "        unique1, counts1 = np.unique(targetAttributesList, return_counts=True)\n",
    "        dictOfTaAttr = dict(zip(unique1, counts1))\n",
    "        posCount = dictOfTaAttr[1]\n",
    "        negCount = dictOfTaAttr[0]\n",
    "        if (posCount/(posCount+negCount))>0.24:\n",
    "            r = Node(examplesForCurNode,'leafNode','leafNode','Positive',level)\n",
    "            #numberOfNodes  = numberOfNodes + 1\n",
    "        else:\n",
    "            r = Node(examplesForCurNode,'leafNode','leafNode','Negative',level)\n",
    "            #numberOfNodes  = numberOfNodes + 1\n",
    "        print(r)\n",
    "        print(\"Type8\")\n",
    "        return r \n",
    "    \n",
    "    if BestAttribute in NumericalAttributes:\n",
    "        BestAttributeType = 'numerical'\n",
    "    else:\n",
    "        BestAttributeType = 'categorical'\n",
    "    r = Node(examplesForCurNode,BestAttributeType,BestAttribute,BestAttributeValue,level)\n",
    "    print(r)\n",
    "    print(\"Type4\")\n",
    "    #numberOfNodes  = numberOfNodes + 1\n",
    "    examplesForLeftChildOfCurrentNode = []\n",
    "    examplesForRightChildOfCurrentNode = []        \n",
    "    if BestAttributeType == 'categorical':        \n",
    "        for iter1 in examplesForCurNode:\n",
    "            if  str(train.at[int(iter1),str(BestAttribute)]) == str(BestAttributeValue):\n",
    "                examplesForLeftChildOfCurrentNode.append(int(iter1))\n",
    "            else:\n",
    "                examplesForRightChildOfCurrentNode.append(int(iter1))\n",
    "    else:\n",
    "        for iter1 in examplesForCurNode:\n",
    "            if  float(str(train.at[int(iter1),str(BestAttribute)])) <= float(str(BestAttributeValue)):\n",
    "                examplesForLeftChildOfCurrentNode.append(int(iter1))\n",
    "            else:\n",
    "                examplesForRightChildOfCurrentNode.append(int(iter1))\n",
    "    fra1 = train.loc[examplesForCurNode,[targetAttribute] ]\n",
    "    targetAttributesList = fra1[targetAttribute].values\n",
    "    unique1, counts1 = np.unique(targetAttributesList, return_counts=True)\n",
    "    dictOfTaAttr = dict(zip(unique1, counts1))\n",
    "    posCount = dictOfTaAttr[1]\n",
    "    negCount = dictOfTaAttr[0]\n",
    "    if len(examplesForLeftChildOfCurrentNode)!=0:\n",
    "        r.leftChild = DecisionTreeBuilder(examplesForLeftChildOfCurrentNode,targetAttribute,level+1,method)\n",
    "    else:\n",
    "        if (posCount/(posCount+negCount))>0.24:\n",
    "            r.leftChild = Node(examplesForCurNode,'leafNode','leafNode','Positive',level)\n",
    "        else:\n",
    "            r.leftChild = Node(examplesForCurNode,'leafNode','leafNode','Negative',level)\n",
    "    \n",
    "    if len(examplesForRightChildOfCurrentNode)!=0:\n",
    "        r.rightChild = DecisionTreeBuilder(examplesForRightChildOfCurrentNode,targetAttribute,level+1,method)\n",
    "    else:\n",
    "        if (posCount/(posCount+negCount))>0.24:\n",
    "            r.rightChild = Node(examplesForCurNode,'leafNode','leafNode','Positive',level)\n",
    "        else:\n",
    "            r.rightChild = Node(examplesForCurNode,'leafNode','leafNode','Negative',level)          \n",
    "   \n",
    "    return r \n",
    "def CalulatePrecsionRecallEtc(GivenTestData):\n",
    "    GivenTestData['predict']= [0]*len(GivenTestData)\n",
    "    for i in list(GivenTestData.index.values):        \n",
    "        GivenTestData.at[i,'predict'] = RecursiveFunctionToPredict(i,RootNode,GivenTestData)\n",
    "\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TP = 0\n",
    "    for i in list(GivenTestData.index.values):\n",
    "        if str(GivenTestData.at[i,'left']) == str(1) and str(GivenTestData.at[i,'predict']) == str(1):\n",
    "            TP = TP + 1\n",
    "        elif str(GivenTestData.at[i,'left']) == str(1) and str(GivenTestData.at[i,'predict']) == str(0):\n",
    "            FN = FN + 1\n",
    "        elif str(GivenTestData.at[i,'left']) == str(0) and str(GivenTestData.at[i,'predict']) == str(1):\n",
    "            FP = FP + 1\n",
    "        elif str(GivenTestData.at[i,'left']) == str(0) and str(GivenTestData.at[i,'predict']) == str(0):\n",
    "            TN = TN + 1\n",
    "    print(\"Results On GivenTestData\")\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(\"True Positive are    \"+ str(TP))\n",
    "    print(\"True Negatives are   \"+ str(TN))\n",
    "    print(\"False Positive are   \"+ str(FP))\n",
    "    print(\"False Negatives are  \"+str(FN))\n",
    "\n",
    "    Precision = (TP/(TP+FP))\n",
    "    Recall = (TP/(TP+FN))\n",
    "    F1_Score = 2*((1/Recall)+(1/Precision))\n",
    "    accuracy = (TN+TP)/(TN+TP+FP+FN)\n",
    "    print(\"Precsion is          \"+str(Precision))\n",
    "    print(\"Recall is            \"+str(Recall))\n",
    "    print(\"F1_Score is          \"+str(F1_Score))\n",
    "    print(\"Accuracy is          \"+str(accuracy))\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(\"( Here 1's  are positive 0's are negative)\")\n",
    "\n",
    "    return GivenTestData\n",
    "\n",
    "\n",
    "def RecursiveFunctionToPredict(i,r,TestSet):\n",
    "    if r.decisionAttribute == 'leafNode':\n",
    "        if r.decisionAttributeValue == 'Positive':\n",
    "            return '1'\n",
    "        else:\n",
    "            return '0'\n",
    "    else:\n",
    "        if r.decisionAttributeType == 'categorical':            \n",
    "            AttrValue = str(TestSet.at[int(i),str(r.decisionAttribute)])            \n",
    "            if AttrValue == str(r.decisionAttributeValue):\n",
    "                return RecursiveFunctionToPredict(i,r.leftChild,TestSet)\n",
    "            else:\n",
    "                return RecursiveFunctionToPredict(i,r.rightChild,TestSet)            \n",
    "        elif r.decisionAttributeType == 'numerical':            \n",
    "            AttrValue = float(str(TestSet.at[int(i),str(r.decisionAttribute)]))            \n",
    "            if AttrValue <= float(str(r.decisionAttributeValue)):\n",
    "                return RecursiveFunctionToPredict(i,r.leftChild,TestSet)\n",
    "            else:\n",
    "                return RecursiveFunctionToPredict(i,r.rightChild,TestSet)\n",
    "\n",
    "def predict(RootNode,NameOfTestFile):\n",
    "    GivenTestData = pd.read_csv(str(NameOfTestFile))\n",
    "    GivenTestData['predict']= [0]*len(GivenTestData)\n",
    "    for i in list(GivenTestData.index.values):        \n",
    "        GivenTestData.at[i,'predict'] = RecursiveFunctionToPredict(i,RootNode,GivenTestData)\n",
    "    \n",
    "    return GivenTestData            \n",
    "\n",
    "\n",
    "examplesForRootNode = examples[:]\n",
    "method = 'Entropy'\n",
    "\n",
    "RootNode = DecisionTreeBuilder(examplesForRootNode,targetAttribute,0,method)\n",
    "\n",
    "Prediction = predict(RootNode,'sample_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results On GivenTestData\n",
      "-------------------------------------------------\n",
      "True Positive are    14\n",
      "True Negatives are   3\n",
      "False Positive are   4\n",
      "False Negatives are  0\n",
      "Precsion is          0.7777777777777778\n",
      "Recall is            1.0\n",
      "F1_Score is          4.571428571428571\n",
      "Accuracy is          0.8095238095238095\n",
      "Error is             0.19047619047619047\n",
      "-------------------------------------------------\n",
      "( Here 1's  are positive 0's are negative)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'numberOfNodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ad3f3e7c8ddb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mGivenTestData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mCalulatePrecsionRecallEtc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGivenTestData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"numberOfNodes \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumberOfNodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'numberOfNodes' is not defined"
     ]
    }
   ],
   "source": [
    "def CalulatePrecsionRecallEtc1(GivenTestData):\n",
    "    GivenTestData['predict']= [0]*len(GivenTestData)\n",
    "    for i in list(GivenTestData.index.values):        \n",
    "        GivenTestData.at[i,'predict'] = RecursiveFunctionToPredict(i,RootNode,GivenTestData)\n",
    "\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TP = 0\n",
    "    for i in list(GivenTestData.index.values):\n",
    "        if str(GivenTestData.at[i,'left']) == str(1) and str(GivenTestData.at[i,'predict']) == str(1):\n",
    "            TP = TP + 1\n",
    "        elif str(GivenTestData.at[i,'left']) == str(1) and str(GivenTestData.at[i,'predict']) == str(0):\n",
    "            FN = FN + 1\n",
    "        elif str(GivenTestData.at[i,'left']) == str(0) and str(GivenTestData.at[i,'predict']) == str(1):\n",
    "            FP = FP + 1\n",
    "        elif str(GivenTestData.at[i,'left']) == str(0) and str(GivenTestData.at[i,'predict']) == str(0):\n",
    "            TN = TN + 1\n",
    "    print(\"Results On GivenTestData\")\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(\"True Positive are    \"+ str(TP))\n",
    "    print(\"True Negatives are   \"+ str(TN))\n",
    "    print(\"False Positive are   \"+ str(FP))\n",
    "    print(\"False Negatives are  \"+str(FN))\n",
    "    Error =(FN+FP)/(TP+TN+FN+FP)\n",
    "    Precision = (TP/(TP+FP))\n",
    "    Recall = (TP/(TP+FN))\n",
    "    F1_Score = 2*((1/Recall)+(1/Precision))\n",
    "    accuracy = (TN+TP)/(TN+TP+FP+FN)\n",
    "    print(\"Precsion is          \"+str(Precision))\n",
    "    print(\"Recall is            \"+str(Recall))\n",
    "    print(\"F1_Score is          \"+str(F1_Score))\n",
    "    print(\"Accuracy is          \"+str(accuracy))\n",
    "    print(\"Error is             \"+str(Error))\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(\"( Here 1's  are positive 0's are negative)\")\n",
    "val = val.drop_duplicates(subset=None, keep=False, inplace=False)\n",
    "GivenTestData = val.copy()\n",
    "CalulatePrecsionRecallEtc1(GivenTestData)\n",
    "print(\"numberOfNodes \"+str(numberOfNodes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
