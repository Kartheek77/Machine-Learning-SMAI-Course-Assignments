{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMethodImpurity(numericalAttribute,value,examplesForCurAttr,method):\n",
    "    #print(\"calculating Impurity\")\n",
    "    \n",
    "    fra1 = train.loc[examplesForCurAttr,:]\n",
    "    LessThanExamples = []\n",
    "    MoreThanExamples = []\n",
    "    for j in examplesForCurAttr:\n",
    "        if  float(str(train.at[int(j),numericalAttribute])) <= value:\n",
    "            LessThanExamples.append(int(j))\n",
    "        else:\n",
    "            MoreThanExamples.append(int(j))\n",
    "    if len(LessThanExamples) ==0 or len(MoreThanExamples) == 0:    \n",
    "        print(\"I am here and there is a problem\")\n",
    "    if len(LessThanExamples) ==0 or len(MoreThanExamples) == 0:\n",
    "        return 999\n",
    "    else:\n",
    "        if getEntropyOfExamples(LessThanExamples) ==0 or getEntropyOfExamples(MoreThanExamples) == 0:\n",
    "            print(\"yes i am here kartheek\")        \n",
    "        return ((len(LessThanExamples)*getEntropyOfExamples(LessThanExamples))+(len(MoreThanExamples)*getEntropyOfExamples(MoreThanExamples)))/len(examplesForCurAttr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntropyOfExamples(examplesForCurAttr):\n",
    "    NumberOfPosEx = 0\n",
    "    NumberOfNegEx = 0\n",
    "    for j in examplesForCurAttr:\n",
    "        if  str(train.at[int(j),targetAttribute]) == str(1):\n",
    "            NumberOfPosEx = NumberOfPosEx+1\n",
    "        elif str(train.at[int(j),targetAttribute]) == str(0):\n",
    "             NumberOfNegEx = NumberOfNegEx+1\n",
    "    PropOfPos =  NumberOfPosEx/len(examplesForCurAttr)\n",
    "    PropOfNeg = NumberOfNegEx/len(examplesForCurAttr)\n",
    "    if PropOfPos == 0:\n",
    "        return (-1*PropOfNeg*(np.log(PropOfNeg)/np.log(2)))\n",
    "    elif PropOfNeg == 0:\n",
    "        return (-1*PropOfPos*(np.log(PropOfPos)/np.log(2)))\n",
    "    else:\n",
    "        return ((-1*PropOfPos*(np.log(PropOfPos)/np.log(2))) + (-1*PropOfNeg*(np.log(PropOfNeg)/np.log(2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self,examples,decisionAttributeType,decisionAttribute,decisionAttributeValue,level):\n",
    "        self.examples = examples\n",
    "        self.decisionAttributeType = decisionAttributeType\n",
    "        self.decisionAttribute = decisionAttribute        \n",
    "        self.decisionAttributeValue = decisionAttributeValue\n",
    "        self.level = level\n",
    "        self.leftChild = None\n",
    "        self.rightChild = None\n",
    "        \n",
    "    def __str__(self): \n",
    "        return \"Decision attribute type is \"+self.decisionAttributeType+\"decisionAttribute is \"+ self.decisionAttribute+\" decisionAttributeValue is \"+ str(self.decisionAttributeValue)+\" of level \"+str(self.level)+\" number of examples of this node \"+str(len(self.examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BestOfAttributes(examplesForCurAttr,targetAttribute,method):\n",
    "    entropyForCurrentExamples = getEntropyOfExamples(examplesForCurAttr)\n",
    "    EntropyForCategoricalAttributes = {}\n",
    "    for i in CategoricalAttributes:\n",
    "        EntropyForCategoricalAttributes[i] = getImpurity(i,examplesForCurAttr,targetAttribute,method)\n",
    "    BestOfCategoricalAttributes = min(EntropyForCategoricalAttributes, key=EntropyForCategoricalAttributes.get)\n",
    "    BestOfCategoricalAttributesValue = min(list(EntropyForCategoricalAttributes.values()))\n",
    "    dictForCategAttrUniqueValues = {}\n",
    "    for i in NumericalAttributes:\n",
    "        dictForNumAttrUniqueValues[i] = list(fra1[i].sort_values().unique())\n",
    "    dictForEntropyUniqueValue = dictForNumAttrUniqueValues.copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    fra1 = train.loc[examplesForCurAttr,NumericalAttributes]\n",
    "    #fra2 = fra1[:]\n",
    "    #print(fra1)\n",
    "    dictForNumAttrUniqueValues = {}\n",
    "    for i in NumericalAttributes:\n",
    "        dictForNumAttrUniqueValues[i] = list(fra1[i].sort_values().unique())\n",
    "    dictForEntropyUniqueValue = dictForNumAttrUniqueValues.copy()\n",
    "    print(dictForNumAttrUniqueValues)\n",
    "    for i in NumericalAttributes:\n",
    "        for j,val in enumerate(dictForNumAttrUniqueValues[i]):\n",
    "            dictForEntropyUniqueValue[i][j] = getMethodImpurity(i,dictForNumAttrUniqueValues[i][j],examplesForCurAttr,method)          \n",
    "    EntropyValuesForNumericalAttributes = {}\n",
    "    for i in NumericalAttributes:\n",
    "        EntropyValuesForNumericalAttributes[i]=min(dictForEntropyUniqueValue[i])\n",
    "    BestOfNumericalAttributes = min(EntropyValuesForNumericalAttributes, key=EntropyValuesForNumericalAttributes.get)\n",
    "    BestOfNumericalAttributesValue = min(EntropyValuesForNumericalAttributes.values())\n",
    "    for i in dictForNumAttrUniqueValues[BestOfNumericalAttributes]:\n",
    "        if i == BestOfNumericalAttributesValue:\n",
    "            break\n",
    "    BestSplitValue = i       \n",
    "    if len(Attributes) > 5:\n",
    "        if BestOfNumericalAttributesValue < BestOfCategoricalAttributesValue:\n",
    "            return BestOfNumericalAttributes,BestSplitValue\n",
    "        else: \n",
    "            return BestOfCategoricalAttributes,0\n",
    "    else:\n",
    "        return BestOfNumericalAttributes,BestSplitValue  \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTreeBuilder(examplesForCurNode,targetAttribute,level):\n",
    "    allExPos = True\n",
    "    for i in examplesForCurNode:\n",
    "        if str(train.at[int(i),targetAttribute]) == str(1):\n",
    "            pass\n",
    "        else:\n",
    "            allExPos = False\n",
    "            break\n",
    "    if allExPos:        \n",
    "        r = Node(examplesForCurNode,'leafNode','leafNode','Positive',level)\n",
    "        print(r)\n",
    "        print(\"Type1\")\n",
    "        return r\n",
    "    allExNeg = True\n",
    "    for j in examplesForCurNode:\n",
    "        if str(train.at[j,targetAttribute]) == str(0):\n",
    "            pass\n",
    "        else:\n",
    "            allExNeg = False\n",
    "            break\n",
    "    if allExNeg:\n",
    "        r = Node(examplesForCurNode,'leafNode','leafNode','Negative',level)\n",
    "        print(r)\n",
    "        print(\"Type2\")\n",
    "        return r\n",
    "    if getEntropyOfExamples(examplesForCurNode) < 0.01 or len(examplesForCurNode)<50:\n",
    "        fra1 = train.loc[examplesForCurNode,[targetAttribute] ]\n",
    "        targetAttributesList = fra1[targetAttribute].values\n",
    "        unique1, counts1 = np.unique(targetAttributesList, return_counts=True)\n",
    "        dictOfTaAttr = dict(zip(unique1, counts1))\n",
    "        posCount = dictOfTaAttr[1]\n",
    "        negCount = dictOfTaAttr[0]\n",
    "        if (posCount/(posCount+negCount))>0.5:\n",
    "            r = Node(examplesForCurNode,'leafNode','leafNode','Positive',level)\n",
    "            numberOfNodes  = numberOfNodes + 1\n",
    "        else:\n",
    "            r = Node(examplesForCurNode,'leafNode','leafNode','Negative',level)\n",
    "            numberOfNodes  = numberOfNodes + 1\n",
    "        print(r)\n",
    "        print(\"Type3\")\n",
    "        return r\n",
    "    \n",
    "    BestAttribute,BestAttributeValue = BestOfAttributes(examplesForCurNode,targetAttribute,'misClasifi')\n",
    "    \n",
    "    if BestAttribute in NumericalAttributes:\n",
    "        BestAttributeType = 'numerical'\n",
    "    else:\n",
    "        BestAttributeType = 'categorical'\n",
    "    \n",
    "    r = Node(examplesForCurNode,BestAttributeType,BestAttribute,BestAttributeValue,level)\n",
    "    print(r)\n",
    "    print(\"Type4\")\n",
    "    numberOfNodes  = numberOfNodes + 1\n",
    "    examplesForLeftChildOfCurrentNode = []\n",
    "    examplesForRightChildOfCurrentNode = []        \n",
    "    if BestAttributeType == 'categorical':        \n",
    "        for iter1 in examplesForCurNode:\n",
    "            if  str(train.at[int(iter1),str(BestAttribute)]) == str(BestAttributeValue):\n",
    "                examplesForLeftChildOfCurrentNode.append(int(iter1))\n",
    "            else:\n",
    "                examplesForRightChildOfCurrentNode.append(int(iter1))\n",
    "    else:\n",
    "        for iter1 in examplesForCurNode:\n",
    "            if  float(str(train.at[int(iter1),str(BestAttribute)])) <= float(str(BestAttributeValue)):\n",
    "                examplesForLeftChildOfCurrentNode.append(int(iter1))\n",
    "            else:\n",
    "                examplesForRightChildOfCurrentNode.append(int(iter1))\n",
    "        \n",
    "    r.leftChild = DecisionTreeBuilder(examplesForLeftChildOfCurrentNode,targetAttribute,level+1)\n",
    "    r.rightChild = DecisionTreeBuilder(examplesForRightChildOfCurrentNode,targetAttribute,level+1)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(i,r,TestSet):\n",
    "    if r.decisionAttribute == 'leafNode':\n",
    "        if r.decisionAttributeValue == 'Positive':\n",
    "            return '1'\n",
    "        else:\n",
    "            #print(\"I am here in leaft\")\n",
    "            return '0'\n",
    "    else:\n",
    "        if r.decisionAttributeType == 'categorical': \n",
    "            \n",
    "            AttrValue = str(TestSet.at[int(i),str(r.decisionAttribute)])\n",
    "            \n",
    "            if AttrValue == str(r.decisionAttributeValue):\n",
    "                return predict(i,r.leftChild,TestSet)\n",
    "            else:\n",
    "                return predict(i,r.rightChild,TestSet)\n",
    "            \n",
    "        elif r.decisionAttributeType == 'numerical':\n",
    "            \n",
    "            AttrValue = float(str(TestSet.at[int(i),str(r.decisionAttribute)]))\n",
    "            \n",
    "            if AttrValue <= float(str(r.decisionAttributeValue)):\n",
    "                return predict(i,r.leftChild,TestSet)\n",
    "            else:\n",
    "                return predict(i,r.rightChild,TestSet)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
