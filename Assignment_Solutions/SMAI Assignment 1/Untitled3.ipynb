{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>3</td>\n",
       "      <td>236</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>product_mng</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.54</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>accounting</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.69             0.69               3                   236   \n",
       "1                0.36             0.54               2                   153   \n",
       "\n",
       "   time_spend_company  Work_accident  promotion_last_5years        sales  \\\n",
       "0                   4              0                      0  product_mng   \n",
       "1                   3              1                      0   accounting   \n",
       "\n",
       "   salary  predict  \n",
       "0  medium        0  \n",
       "1  medium        0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "#reading the given data \n",
    "data = pd.read_csv(\"train.csv\") \n",
    "\n",
    "#Creating a training data and validation data\n",
    "ran = np.random.rand(len(data)) < 0.8\n",
    "train = data[ran]\n",
    "val = data[~ran]\n",
    "\n",
    "#Considering only categorical data for part1 of the question\n",
    "train = train.loc[:,['Work_accident', 'promotion_last_5years', 'sales', 'salary','left'] ]\n",
    "val = val.loc[:,['Work_accident', 'promotion_last_5years', 'sales', 'salary','left'] ]\n",
    "\n",
    "#Variable for numberOfNodes(just to have a rough idea)\n",
    "numberOfNodes = 0\n",
    "\n",
    "#Class definition for Nodes in Decision Tree\n",
    "class Node(object):\n",
    "    #def __init__(self, label,name,parentAttrValue,nodeNumber,level):\n",
    "    def __init__(self, examples, attributes, decisionAttribute, nodeNumber, parentDecisionAttribute, parentDecisionAttributeValue, decision, level):\n",
    "        self.examples = examples\n",
    "        self.attributes = attributes\n",
    "        self.decisionAttribute = decisionAttribute \n",
    "        self.nodeNumber = nodeNumber\n",
    "        self.children = []\n",
    "        self.parentDecisionAttribute = parentDecisionAttribute\n",
    "        self.parentDecisionAttributeValue = parentDecisionAttributeValue\n",
    "        self.decision = decision\n",
    "        self.level = level\n",
    "\n",
    "    def add_child(self, obj):\n",
    "        self.children.append(obj)\n",
    "        \n",
    "    def increment_nodeNumber(self):\n",
    "        #nodeNumber = nodeNumber+1\n",
    "        self.nodeNumber = self.nodeNumber + 1\n",
    "        \n",
    "    def __str__(self):\n",
    "        #return self.label +\"  \"+ self.name+\"  \"+self.parentAttrValue+\"Node number is \"+ str(self.nodeNumber)+\" of level \"+str(self.level)\n",
    "        return \"Decision attribute for this node is \"+self.decisionAttribute+\" decision \"+ self.decision+\" Node number is \"+ str(self.nodeNumber)+\" of level \"+str(self.level)+\" number of examples of this node \"+str(len(self.examples))\n",
    "    \n",
    "\n",
    "#Defining the targetAttribute(Label) column, list of attributes is extracted from data, examples refer to samples(rows) in data \n",
    "targetAttribute = 'left'\n",
    "Attributes = list(train.columns)\n",
    "Attributes.remove(targetAttribute)\n",
    "AllAttrExpTar = Attributes[:]\n",
    "examples = list(train.index.values) \n",
    "\n",
    "#Function for calculating the total entropy associated with all samples at a node\n",
    "def getEntropyOfExamples(examplesForCurAttr):\n",
    "    NumberOfPosEx = 0\n",
    "    NumberOfNegEx = 0\n",
    "    for j in examplesForCurAttr:\n",
    "        if  str(train.at[int(j),targetAttribute]) == str(1):\n",
    "            NumberOfPosEx = NumberOfPosEx+1\n",
    "        elif str(train.at[int(j),targetAttribute]) == str(0):\n",
    "             NumberOfNegEx = NumberOfNegEx+1\n",
    "    PropOfPos =  NumberOfPosEx/len(examplesForCurAttr)\n",
    "    PropOfNeg = NumberOfNegEx/len(examplesForCurAttr)\n",
    "    return ((-1*PropOfPos*(np.log(PropOfPos)/np.log(2))) + (-1*PropOfNeg*(np.log(PropOfNeg)/np.log(2))))\n",
    "\n",
    "\n",
    "#Function for calculating the entropy of a attribute for given examples(Used while determining the Best Attribute for a node)\n",
    "def getEntropyofAttribute(currentAttribute,examplesForCurAttr,targetAttribute):\n",
    "    NumberOfexamplesForCurAttr = len(examplesForCurAttr)\n",
    "    sum = 0.0\n",
    "    fra1 = train.loc[examplesForCurAttr,[currentAttribute] ]\n",
    "    currentAttributeValues = fra1[currentAttribute].unique()\n",
    "    for i in currentAttributeValues:\n",
    "        NumberOfExaForThisValue = 0\n",
    "        for j in examplesForCurAttr:\n",
    "            if str(train.at[int(j),currentAttribute]) == str(i):\n",
    "                NumberOfExaForThisValue = NumberOfExaForThisValue+1\n",
    "        if NumberOfExaForThisValue == 0:\n",
    "            sum = sum+0\n",
    "        else:\n",
    "            NumberOfPosForThisValue = 0\n",
    "            NumberOfNegForThisValue = 0\n",
    "            for j in examplesForCurAttr:\n",
    "                if str(train.at[int(j),targetAttribute]) == str(1) and str(train.at[int(j),currentAttribute]) == str(i):\n",
    "                    NumberOfPosForThisValue = NumberOfPosForThisValue+1\n",
    "                elif str(train.at[int(j),targetAttribute]) == str(0) and str(train.at[int(j),currentAttribute]) == str(i):\n",
    "                    NumberOfNegForThisValue = NumberOfNegForThisValue+1\n",
    "            PropOfPos = NumberOfPosForThisValue/NumberOfExaForThisValue\n",
    "            PropOfNeg = NumberOfNegForThisValue/NumberOfExaForThisValue\n",
    "            PropOfThisValue = NumberOfExaForThisValue/NumberOfexamplesForCurAttr\n",
    "            if PropOfPos == 0:\n",
    "                sum = sum + ((PropOfThisValue)*(-1*PropOfNeg*(np.log(PropOfNeg)/np.log(2))))\n",
    "            elif PropOfNeg == 0:\n",
    "                sum = sum + ((PropOfThisValue)*(-1*PropOfPos*(np.log(PropOfPos)/np.log(2))))\n",
    "            else:\n",
    "                sum = sum + ((PropOfThisValue)*((-1*PropOfPos*(np.log(PropOfPos)/np.log(2))) + (-1*PropOfNeg*(np.log(PropOfNeg)/np.log(2)))))              \n",
    "    return sum\n",
    "\n",
    "\n",
    "#Function to calclulate the best attribute at a node\n",
    "def BestOfAttributes(Attributes,examplesForCurAttr,targetAttribute,method):\n",
    "    if len(Attributes) == 1:\n",
    "        return Attributes[0]\n",
    "    elif method == 'Entropy':\n",
    "        EntropyForAttributes = {}\n",
    "        for i in Attributes:\n",
    "            EntropyForAttributes[i] = getEntropyofAttribute(i,examplesForCurAttr,targetAttribute)\n",
    "        #findining the minimum among entropy of attributes\n",
    "        BestOfAttributes = min(EntropyForAttributes, key=EntropyForAttributes.get)\n",
    "        return BestOfAttributes        \n",
    "    elif method == 'Gini':\n",
    "        pass\n",
    "    elif method == 'misClasifi':\n",
    "        pass\n",
    "    return BestOfAttributes\n",
    "\n",
    "#Function which constructs the decision tree \n",
    "def DecisionTreeBuilder(examplesForCurNode,targetAttribute,AttributesForCurrentNode,parentDecisionAttribute,parentAttrValue,level):  \n",
    "    \n",
    "    global numberOfNodes\n",
    "    \n",
    "    # if all samples are positive(i.e employee left the company,left =1 )\n",
    "    allExPos = True\n",
    "    for i in examplesForCurNode:\n",
    "        if str(train.at[int(i),targetAttribute]) == str(1):\n",
    "            pass\n",
    "        else:\n",
    "            allExPos = False\n",
    "            break\n",
    "    if allExPos:\n",
    "        r = Node(examplesForCurNode,AttributesForCurrentNode,'leafNode',numberOfNodes,parentDecisionAttribute,parentAttrValue,'Positive',level)\n",
    "        numberOfNodes  = numberOfNodes + 1\n",
    "        return r\n",
    "    \n",
    "    # if all samples are negative(i.e employee didnot leave the company,left =0 )\n",
    "    allExNeg = True\n",
    "    for j in examplesForCurNode:\n",
    "        if str(train.at[j,targetAttribute]) == str(0):\n",
    "            pass\n",
    "        else:\n",
    "            allExNeg = False\n",
    "            break\n",
    "    if allExNeg:\n",
    "        r = Node(examplesForCurNode,AttributesForCurrentNode,'leafNode',numberOfNodes,parentDecisionAttribute,parentAttrValue,'Negative',level)\n",
    "        numberOfNodes  = numberOfNodes + 1\n",
    "        return r\n",
    "    \n",
    "    #if attributes are exhausted\n",
    "    if len(AttributesForCurrentNode) == 0 or getEntropyOfExamples(examplesForCurNode) < 0.01:#or len(examplesForCurNode)<50 :\n",
    "        fra1 = train.loc[examplesForCurNode,[targetAttribute] ]\n",
    "        targetAttributesList = fra1[targetAttribute].values\n",
    "        unique1, counts1 = np.unique(targetAttributesList, return_counts=True)\n",
    "        dictOfTaAttr = dict(zip(unique1, counts1))\n",
    "        posCount = dictOfTaAttr[1]\n",
    "        negCount = dictOfTaAttr[0]\n",
    "        if (posCount/(posCount+negCount))>0.24:\n",
    "            r = Node(examplesForCurNode,AttributesForCurrentNode,'leafNode',numberOfNodes,parentDecisionAttribute,parentAttrValue,'Positive',level)\n",
    "            numberOfNodes  = numberOfNodes + 1\n",
    "        else:\n",
    "            r = Node(examplesForCurNode,AttributesForCurrentNode,'leafNode',numberOfNodes,parentDecisionAttribute,parentAttrValue,'Negative',level)\n",
    "            numberOfNodes  = numberOfNodes + 1\n",
    "        return r\n",
    "    \n",
    "    #If none of the above were conditions were true then find the best attribute and create children accordingly\n",
    "    BestAttribute = BestOfAttributes(AttributesForCurrentNode,examplesForCurNode,targetAttribute,'Entropy')    \n",
    "    r = Node(examplesForCurNode,AttributesForCurrentNode,BestAttribute,numberOfNodes,parentDecisionAttribute,parentAttrValue,'NotLeaf',level)\n",
    "    numberOfNodes  = numberOfNodes + 1\n",
    "    BestAttributeValues = list(data[BestAttribute].unique())\n",
    "    for iter in BestAttributeValues:\n",
    "        AttributesForChildren = []\n",
    "        AttributesForChildren = AttributesForCurrentNode[:]\n",
    "        AttributesForChildren.remove(BestAttribute)\n",
    "        examplesForThisChildOfCurrentNode = []\n",
    "        for iter1 in examplesForCurNode:\n",
    "            if  str(train.at[int(iter1),str(BestAttribute)]) == str(iter):\n",
    "                examplesForThisChildOfCurrentNode.append(int(iter1))\n",
    "        if len(examplesForThisChildOfCurrentNode)==0:\n",
    "            numberOfNodes  = numberOfNodes + 1\n",
    "            fra1 = train.loc[examplesForCurNode,[targetAttribute] ]\n",
    "            targetAttributesList = fra1[targetAttribute].values\n",
    "            unique1, counts1 = np.unique(targetAttributesList, return_counts=True)\n",
    "            dictOfTaAttr = dict(zip(unique1, counts1))\n",
    "            posCount = dictOfTaAttr[1]\n",
    "            negCount = dictOfTaAttr[0]\n",
    "            if (posCount/(posCount+negCount))>0.24:\n",
    "                r.add_child(Node(examplesForThisChildOfCurrentNode,AttributesForChildren,'leafNode',numberOfNodes,BestAttribute,str(iter),'Positive',level+1))\n",
    "            else:\n",
    "                r.add_child(Node(examplesForThisChildOfCurrentNode,AttributesForChildren,'leafNode',numberOfNodes,BestAttribute,str(iter),'Negative',level+1))                            \n",
    "            numberOfNodes = numberOfNodes - 1\n",
    "        else:        \n",
    "            r.add_child(DecisionTreeBuilder(examplesForThisChildOfCurrentNode,targetAttribute,AttributesForChildren,BestAttribute,str(iter),level+1))            \n",
    "    return r\n",
    "\n",
    "numberOfNodes = 0\n",
    "examplesForRootNode = examples[:]\n",
    "AttributesForRootNode = Attributes[:]\n",
    "\n",
    "#Building the tree from training data \n",
    "RootNode = DecisionTreeBuilder(examplesForRootNode,targetAttribute,AttributesForRootNode,'root','root',0)\n",
    "\n",
    "\n",
    "#Creating a copy of training and validation data to print the predicted value and also calculate precision, recall, accuracy etc\n",
    "valCopy = val.copy()\n",
    "valCopy['predict']= [0]*len(valCopy)\n",
    "trainCopy = train.copy()\n",
    "trainCopy['predict'] = [0]*len(trainCopy)\n",
    "trainExamples = list(train.index.values)\n",
    "valExamples = list(val.index.values)\n",
    "\n",
    "#function definition to predict on given TestSet\n",
    "def RecursiveFunctionToPredict(i,r,TestSet):\n",
    "    if r.decisionAttribute == 'leafNode':\n",
    "        if r.decision == 'Positive':\n",
    "            return '1'\n",
    "        else:\n",
    "            return '0'\n",
    "    else:\n",
    "        AttrValue = str(TestSet.at[int(i),str(r.decisionAttribute)])\n",
    "        for j in r.children:\n",
    "            if str(j.parentDecisionAttributeValue) == str(AttrValue):\n",
    "                break\n",
    "        return RecursiveFunctionToPredict(i,j,TestSet)\n",
    "\n",
    "def predict(RootNode,NameOfTestFile):\n",
    "    GivenTestData = pd.read_csv(str(NameOfTestFile))\n",
    "    GivenTestData['predict']= [0]*len(GivenTestData)\n",
    "    for i in list(GivenTestData.index.values):        \n",
    "        GivenTestData.at[i,'predict'] = RecursiveFunctionToPredict(i,RootNode,GivenTestData)\n",
    "    return GivenTestData\n",
    "Prediction = predict(RootNode,'sample_test.csv')\n",
    "Prediction.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TP = 0\n",
    "    for i in list(GivenTestData.index.values):\n",
    "        if str(GivenTestData.at[i,'left']) == str(1) and str(GivenTestData.at[i,'predict']) == str(1):\n",
    "            TP = TP + 1\n",
    "        elif str(GivenTestData.at[i,'left']) == str(1) and str(GivenTestData.at[i,'predict']) == str(0):\n",
    "            FN = FN + 1\n",
    "        elif str(GivenTestData.at[i,'left']) == str(0) and str(GivenTestData.at[i,'predict']) == str(1):\n",
    "            FP = FP + 1\n",
    "        elif str(GivenTestData.at[i,'left']) == str(0) and str(GivenTestData.at[i,'predict']) == str(0):\n",
    "            TN = TN + 1\n",
    "    print(TN)\n",
    "    print(FP)\n",
    "    print(FN)\n",
    "    print(TP)\n",
    "    Precision = (TP/(TP+FP))\n",
    "    Recall = (TP/(TP+FN))\n",
    "    print(Precision)\n",
    "    print(Recall)\n",
    "    F1_Score = 2*((1/Recall)+(1/Precision))\n",
    "    print(F1_Score)\n",
    "    accuracy = (TN+TP)/(TN+TP+FP+FN)\n",
    "    print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
